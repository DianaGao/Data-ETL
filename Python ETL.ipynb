{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the imported data\n",
    "dbname = 'FinanceExplainedDb'\n",
    "conn = sqlite3.connect(dbname + '.sqlite')\n",
    "# Vanish the data after the work done\n",
    "# conn = sqlite3.connect(':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM Table1')\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#if we have a csv file\n",
    "df = pd.read_csv('file.csv')\n",
    "#if we have an excel file\n",
    "df = pd.read_excel('file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading one file\n",
    "df.to_sql(name='Table1', con=conn)\n",
    "# Loading multiple files\n",
    "df.to_sql(name='Table1', con=conn, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Memory consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10000\n",
    "for chunk in pd.read_csv('ourfile.csv', chunksize=chunksize):\n",
    "    chunk.to_sql(name='Table1', con=conn, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: import the csv file (consider the memory)\n",
    "Step2: load into the sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(':memory:')\n",
    "cur = conn.cursor()\n",
    "chunksize = 10\n",
    "for chunk in pd.read_csv('TestData.csv', chunksize=chunksize):\n",
    "    chunk.columns = chunk.columns.str.replace(' ', '_') #replacing spaces with underscores for column names\n",
    "    chunk.to_sql(name='Table1', con=conn, if_exists='append')\n",
    "cur.execute('SELECT * FROM Table1')\n",
    "names = list(map(lambda x: x[0], cur.description)) #Returns the column names\n",
    "# The map() function executes a specified function for each item in a iterable. The item is sent to the function as a parameter.\n",
    "# A lambda function can take any number of arguments, but can only have one expression.\n",
    "#A lambda function is a small anonymous function.\n",
    "\n",
    "print(names)\n",
    "for row in cur:\n",
    "    print(row)\n",
    "cur.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
